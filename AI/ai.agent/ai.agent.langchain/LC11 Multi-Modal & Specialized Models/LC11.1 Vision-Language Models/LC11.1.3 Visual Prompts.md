| **Subtopic**                                   | **Focus & Purpose**                     | **Key Concepts / Details**                                                    | **One-Line Recall**                                             |
| ---------------------------------------------- | --------------------------------------- | ----------------------------------------------------------------------------- | --------------------------------------------------------------- |
| **LC11.1.3.1 Text + Image Prompts**            | Basic pattern                           | Combining instructions with visual context                                    | Ask a question AND provide the image together.                  |
| **LC11.1.3.2 Image-First Prompts**             | Strategy                                | Showing image before asking question for context                              | Put image before text for better grounding.                     |
| **LC11.1.3.3 Few-Shot Visual Examples**        | Learning                                | Showing example images with expected outputs                                  | Provide example image-output pairs for VLMs.                    |
| **LC11.1.3.4 Bounding Box References**         | Precision                               | Referencing specific regions (top-left, red circle, etc.)                     | Describe regions to focus VLM attention.                        |
| **LC11.1.3.5 Chain of Thought for Images**     | Reasoning                               | Asking VLM to describe what it sees THEN answer                               | Make VLM describe first, then conclude.                         |

# Visual Prompts: How to Ask About Images

Prompting VLMs requires **both** good text instructions AND good image presentation.

---

## 1. Text + Image Prompts (Basic)

The simplest pattern: ask a question, attach an image.

```python
message = HumanMessage(
    content=[
        {"type": "text", "text": "Is this a cat or a dog?"},
        {"type": "image_url", "image_url": {"url": image_url}}
    ]
)
```

**Tip**: Be specific. "What animal is this?" is vaguer than "Is this a cat or a dog?"

---

## 2. Image-First Ordering

Some models perform better when you show the image *before* the question.

```python
content = [
    {"type": "image_url", "image_url": {"url": image_url}},
    {"type": "text", "text": "Based on the above image, what is the person's emotion?"}
]
```

The model "sees" the image first, then receives the question.

---

## 3. Few-Shot Visual Examples

Just like text few-shot prompting, you can show example images.

```python
messages = [
    # Example 1
    HumanMessage(content=[
        {"type": "image_url", "image_url": {"url": cat_image_url}},
        {"type": "text", "text": "Classify this animal."}
    ]),
    AIMessage(content="cat"),
    
    # Example 2
    HumanMessage(content=[
        {"type": "image_url", "image_url": {"url": dog_image_url}},
        {"type": "text", "text": "Classify this animal."}
    ]),
    AIMessage(content="dog"),
    
    # Actual query
    HumanMessage(content=[
        {"type": "image_url", "image_url": {"url": new_image_url}},
        {"type": "text", "text": "Classify this animal."}
    ])
]
```

---

## 4. Regional References

If the image has multiple elements, guide the VLM:

```python
"In the top-right corner of the image, there is a logo. What brand is it?"
"Focus on the table with the red cloth. What items are on it?"
```

Models can understand spatial directions like "top-left", "center", "background", etc.

---

## 5. Visual Chain-of-Thought

Make the model describe what it sees BEFORE answering.

```python
"First, describe what you see in this image in detail. 
Then, based on your description, answer: Is this person happy or sad?"
```

This improves accuracy by forcing explicit visual reasoning.

---

## Quick Reference

| Technique | Purpose |
|-----------|---------|
| **Image-First** | Better grounding |
| **Few-Shot** | Teach output format by example |
| **Regional** | Focus on specific areas |
| **VCoT** | Improve reasoning accuracy |
