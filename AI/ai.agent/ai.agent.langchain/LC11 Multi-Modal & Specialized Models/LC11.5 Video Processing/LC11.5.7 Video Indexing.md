| **Subtopic**                                   | **Focus & Purpose**                     | **Key Concepts / Details**                                                    | **One-Line Recall**                                             |
| ---------------------------------------------- | --------------------------------------- | ----------------------------------------------------------------------------- | --------------------------------------------------------------- |
| **LC11.5.7.1 Video Metadata Indexing**         | Basic                                   | Indexing titles, descriptions, tags                                           | Start with basic metadata indexing.                             |
| **LC11.5.7.2 Frame Embedding Index**           | Visual                                  | CLIP embeddings for frame-based search                                        | Index frames with CLIP for visual search.                       |
| **LC11.5.7.3 Transcript Indexing**             | Text                                    | Full-text search on video transcripts                                         | Index transcripts for spoken content search.                    |
| **LC11.5.7.4 Multi-Modal Index**               | Combined                                | Unified search across visual and text                                         | Combine visual and text indexes.                                |
| **LC11.5.7.5 Temporal Indexing**               | Time-based                              | Searching by time and duration                                                | Index timestamps for time-based queries.                        |

# Video Indexing: Making Video Searchable

Transform videos into searchable collections.

---

## 1. Metadata Indexing (Basic)

Start with structured data:

```python
from dataclasses import dataclass
from datetime import datetime

@dataclass
class VideoMetadata:
    video_id: str
    title: str
    description: str
    tags: list[str]
    duration: float
    upload_date: datetime
    file_path: str

class MetadataIndex:
    def __init__(self):
        self.videos = {}
    
    def add(self, metadata: VideoMetadata):
        self.videos[metadata.video_id] = metadata
    
    def search(self, query: str) -> list[VideoMetadata]:
        query_lower = query.lower()
        results = []
        
        for video in self.videos.values():
            if (query_lower in video.title.lower() or
                query_lower in video.description.lower() or
                any(query_lower in tag.lower() for tag in video.tags)):
                results.append(video)
        
        return results
```

---

## 2. Frame Embedding Index

Visual search with CLIP:

```python
from langchain_experimental.open_clip import OpenCLIPEmbeddings
from langchain_chroma import Chroma

class FrameIndex:
    def __init__(self):
        self.embeddings = OpenCLIPEmbeddings()
        self.vectorstore = Chroma(
            collection_name="video_frames",
            embedding_function=self.embeddings
        )
    
    def index_video(self, video_path: str, video_id: str):
        """Index frames from a video."""
        frames = extract_frames(video_path, num_frames=30)
        
        docs = []
        for i, frame_path in enumerate(frames):
            docs.append(Document(
                page_content="",  # CLIP uses image directly
                metadata={
                    "video_id": video_id,
                    "frame_index": i,
                    "frame_path": frame_path,
                    "timestamp": i * (get_duration(video_path) / 30)
                }
            ))
        
        self.vectorstore.add_documents(docs)
    
    def search_visual(self, query: str, k: int = 10):
        """Find frames matching visual description."""
        return self.vectorstore.similarity_search(query, k=k)
```

---

## 3. Transcript Indexing

Full-text search on spoken content:

```python
from langchain_openai import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter

class TranscriptIndex:
    def __init__(self):
        self.embeddings = OpenAIEmbeddings()
        self.vectorstore = Chroma(
            collection_name="video_transcripts",
            embedding_function=self.embeddings
        )
        self.splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50
        )
    
    def index_video(self, video_path: str, video_id: str):
        """Index transcript from video."""
        audio = extract_audio(video_path)
        transcript = transcribe_with_segments(audio)
        
        docs = []
        for segment in transcript.segments:
            docs.append(Document(
                page_content=segment["text"],
                metadata={
                    "video_id": video_id,
                    "start_time": segment["start"],
                    "end_time": segment["end"]
                }
            ))
        
        self.vectorstore.add_documents(docs)
    
    def search_spoken(self, query: str, k: int = 10):
        """Find moments where something was said."""
        return self.vectorstore.similarity_search(query, k=k)
```

---

## 4. Multi-Modal Unified Index

Search across all modalities:

```python
class UnifiedVideoIndex:
    def __init__(self):
        self.frame_index = FrameIndex()
        self.transcript_index = TranscriptIndex()
        self.metadata = MetadataIndex()
    
    def index_video(self, video_path: str, metadata: VideoMetadata):
        """Index all aspects of a video."""
        video_id = metadata.video_id
        
        self.metadata.add(metadata)
        self.frame_index.index_video(video_path, video_id)
        self.transcript_index.index_video(video_path, video_id)
    
    def search(self, query: str, k: int = 10):
        """Unified search across all modalities."""
        # Search all indexes
        frame_results = self.frame_index.search_visual(query, k=k)
        text_results = self.transcript_index.search_spoken(query, k=k)
        meta_results = self.metadata.search(query)
        
        # Combine and deduplicate by video_id
        video_scores = {}
        
        for doc in frame_results:
            vid = doc.metadata["video_id"]
            video_scores[vid] = video_scores.get(vid, 0) + 1
        
        for doc in text_results:
            vid = doc.metadata["video_id"]
            video_scores[vid] = video_scores.get(vid, 0) + 1
        
        # Rank by combined score
        ranked = sorted(video_scores.items(), key=lambda x: -x[1])
        return ranked[:k]
```

---

## 5. Time-Based Indexing

Query by temporal criteria:

```python
def search_by_time(index, video_id: str, start_time: float, end_time: float):
    """Find content within a time range."""
    
    results = index.get_all_for_video(video_id)
    
    return [
        r for r in results
        if r.metadata["start_time"] >= start_time 
        and r.metadata["end_time"] <= end_time
    ]

# Find what was said in first 5 minutes
moments = search_by_time(transcript_index, "vid123", 0, 300)
```

---

## Quick Reference

| Index Type | Searches For |
|------------|--------------|
| **Metadata** | Title, description, tags |
| **Frame** | Visual content ("dog playing") |
| **Transcript** | Spoken words ("mentioned AI") |
| **Multi-Modal** | Any of the above |
| **Temporal** | Specific time ranges |
