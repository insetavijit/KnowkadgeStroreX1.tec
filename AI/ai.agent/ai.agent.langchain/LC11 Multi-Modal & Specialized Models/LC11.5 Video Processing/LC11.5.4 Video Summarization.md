| **Subtopic**                                   | **Focus & Purpose**                     | **Key Concepts / Details**                                                    | **One-Line Recall**                                             |
| ---------------------------------------------- | --------------------------------------- | ----------------------------------------------------------------------------- | --------------------------------------------------------------- |
| **LC11.5.4.1 Key Moment Extraction**           | Highlights                              | Finding the most important moments                                            | Extract key moments for video highlights.                       |
| **LC11.5.4.2 Text Summary Generation**         | Description                             | Creating text summaries of video content                                      | Generate text summaries from video frames.                      |
| **LC11.5.4.3 Chapter Generation**              | Structure                               | Dividing video into logical chapters                                          | Create chapters with timestamps.                                |
| **LC11.5.4.4 Thumbnail Selection**             | Representation                          | Choosing best frame to represent video                                        | Pick the most representative frame.                             |
| **LC11.5.4.5 Condensed Video Creation**        | Compression                             | Creating shorter versions of videos                                           | Create video highlights from key frames.                        |

# Video Summarization: Condensing Visual Content

Long videos need summariesâ€”both text and visual.

---

## 1. Key Moment Extraction

Find the most important frames:

```python
def find_key_moments(frames: list[str], num_moments: int = 5) -> list:
    """Identify the most important moments in a video."""
    
    prompt = f"""
These are frames from a video. Identify the {num_moments} most important moments.

For each key moment, explain:
1. Which frame(s) show it
2. Why it's important
3. What's happening

Rank them by importance.
"""
    
    content = [{"type": "text", "text": prompt}]
    for i, frame in enumerate(frames):
        content.append({"type": "text", "text": f"Frame {i}:"})
        content.append({"type": "image_url", "image_url": {"url": encode(frame)}})
    
    return llm.invoke([HumanMessage(content=content)]).content
```

---

## 2. Text Summary Generation

```python
from pydantic import BaseModel

class VideoSummary(BaseModel):
    title: str
    one_sentence: str
    detailed_summary: str
    key_topics: list[str]
    duration_estimate: str

def summarize_video(frames: list[str]) -> VideoSummary:
    prompt = f"""
Summarize this video based on these representative frames.

{parser.get_format_instructions()}
"""
    
    return summary_chain.invoke({"frames": frames})
```

---

## 3. Chapter Generation

Create YouTube-style chapters:

```python
class Chapter(BaseModel):
    title: str
    start_frame: int
    description: str

class VideoChapters(BaseModel):
    chapters: list[Chapter]

def generate_chapters(frames_with_times: list, fps: float = 30):
    prompt = """
Analyze these video frames and divide the content into logical chapters.

For each chapter, provide:
- Title (short, descriptive)
- Starting frame number
- Brief description

Create 3-7 chapters based on content changes.
"""
    
    chapters = chapter_chain.invoke({"frames": frames_with_times})
    
    # Convert frame numbers to timestamps
    for ch in chapters.chapters:
        ch.timestamp = f"{ch.start_frame / fps:.0f}s"
    
    return chapters
```

---

## 4. Thumbnail Selection

Choose the best representative frame:

```python
def select_thumbnail(frames: list[str]) -> str:
    """Select the best frame to represent the video."""
    
    prompt = """
From these video frames, select ONE that best represents the entire video.

Consider:
- Visual clarity (not blurry)
- Interest (engaging content)
- Context (shows what video is about)
- Faces visible and clear (if applicable)

Respond with the frame number only.
"""
    
    response = llm.invoke([
        HumanMessage(content=[
            {"type": "text", "text": prompt},
            *[{"type": "image_url", "image_url": {"url": encode(f)}} for f in frames]
        ])
    ])
    
    frame_num = int(response.content)
    return frames[frame_num]
```

---

## 5. Highlights Video Creation

Create condensed version from key frames:

```python
import moviepy.editor as mpe

def create_highlights(video_path: str, key_frames: list[int], 
                      clip_duration: float = 2.0) -> str:
    """Create highlight reel from key moments."""
    
    video = mpe.VideoFileClip(video_path)
    fps = video.fps
    
    clips = []
    for frame_num in key_frames:
        start_time = frame_num / fps
        end_time = min(start_time + clip_duration, video.duration)
        
        clip = video.subclip(start_time, end_time)
        clips.append(clip)
    
    # Concatenate all clips
    highlights = mpe.concatenate_videoclips(clips)
    
    output_path = "highlights.mp4"
    highlights.write_videofile(output_path)
    
    return output_path
```

---

## Quick Reference

| Task | Output |
|------|--------|
| **Key Moments** | Frame numbers + descriptions |
| **Text Summary** | Structured text |
| **Chapters** | Timestamps + titles |
| **Thumbnail** | Single best frame |
| **Highlights** | Condensed video file |
