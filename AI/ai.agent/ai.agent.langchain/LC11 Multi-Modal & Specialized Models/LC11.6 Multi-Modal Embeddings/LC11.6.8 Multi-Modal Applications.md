| **Subtopic**                                   | **Focus & Purpose**                     | **Key Concepts / Details**                                                    | **One-Line Recall**                                             |
| ---------------------------------------------- | --------------------------------------- | ----------------------------------------------------------------------------- | --------------------------------------------------------------- |
| **LC11.6.8.1 E-Commerce**                      | Retail                                  | Product image search, visual recommendations                                  | Find products by image or description.                          |
| **LC11.6.8.2 Content Moderation**              | Safety                                  | Detecting inappropriate images                                                | Match images against violation categories.                      |
| **LC11.6.8.3 Knowledge Management**            | Enterprise                              | Searching docs with diagrams                                                  | Search diagrams and text together.                              |
| **LC11.6.8.4 Creative Tools**                  | Design                                  | Finding similar designs, inspiration                                          | Find visual inspiration by description.                         |
| **LC11.6.8.5 Accessibility**                   | Inclusion                               | Auto alt-text, image descriptions                                             | Generate descriptions for accessibility.                        |

# Multi-Modal Applications: Real-World Use Cases

Where cross-modal embeddings solve real problems.

---

## 1. E-Commerce: Visual Product Search

```python
class ProductSearch:
    def __init__(self):
        self.clip = OpenCLIPEmbeddings()
        self.store = Chroma(embedding_function=self.clip)
    
    def index_catalog(self, products: list[dict]):
        """Index product images and descriptions."""
        docs = []
        for p in products:
            docs.append(Document(
                page_content="",
                metadata={
                    "product_id": p["id"],
                    "name": p["name"],
                    "price": p["price"],
                    "image_path": p["image"]
                }
            ))
        self.store.add_documents(docs)
    
    def search_by_text(self, query: str, k: int = 10):
        """Find products by description."""
        return self.store.similarity_search(query, k=k)
    
    def find_similar(self, product_image: str, k: int = 10):
        """Find similar products."""
        emb = self.clip.embed_image(product_image)
        return self.store.similarity_search_by_vector(emb, k=k)

# "Find red dresses under $100"
# "Show me shoes like this one" [upload image]
```

---

## 2. Content Moderation

```python
class ContentModerator:
    def __init__(self):
        self.clip = OpenCLIPEmbeddings()
        
        # Pre-compute violation category embeddings
        self.violation_categories = {
            "violence": "graphic violence, blood, injury, weapons",
            "nsfw": "nudity, explicit content, adult material",
            "hate": "hate symbols, offensive gestures, discrimination"
        }
        
        self.category_embeddings = {
            cat: self.clip.embed_query(desc)
            for cat, desc in self.violation_categories.items()
        }
    
    def check_image(self, image_path: str) -> dict:
        """Check image for violations."""
        img_emb = self.clip.embed_image(image_path)
        
        results = {}
        for cat, cat_emb in self.category_embeddings.items():
            similarity = cosine_sim(img_emb, cat_emb)
            results[cat] = {
                "score": similarity,
                "flagged": similarity > 0.25
            }
        
        return results
```

---

## 3. Enterprise Knowledge Management

```python
class KnowledgeBase:
    """Search across docs, diagrams, screenshots."""
    
    def __init__(self):
        self.mm_store = Chroma(embedding_function=OpenCLIPEmbeddings())
    
    def index_document(self, doc_path: str):
        """Index document text and embedded images."""
        # Extract text
        text_chunks = extract_text(doc_path)
        for chunk in text_chunks:
            self.mm_store.add_documents([Document(page_content=chunk)])
        
        # Extract images
        images = extract_images_from_doc(doc_path)
        for img_path in images:
            self.mm_store.add_documents([Document(
                page_content="",
                metadata={"path": img_path, "source": doc_path}
            )])
    
    def search(self, query: str):
        """Find relevant text AND images."""
        return self.mm_store.similarity_search(query, k=10)

# "Show me the system architecture diagram"
# Returns both text descriptions AND diagram images
```

---

## 4. Creative Tools

```python
def find_design_inspiration(description: str, style_image: str = None):
    """Find designs matching description or style."""
    
    if style_image:
        # Combine text description with visual style
        text_emb = clip.embed_query(description)
        img_emb = clip.embed_image(style_image)
        query_emb = np.mean([text_emb, img_emb], axis=0)
    else:
        query_emb = clip.embed_query(description)
    
    results = design_store.similarity_search_by_vector(query_emb, k=20)
    
    return results

# "minimalist logo with gradient" + [style example image]
```

---

## 5. Accessibility: Auto Alt-Text

```python
def generate_alt_text(image_path: str) -> str:
    """Generate accessible alt-text for image."""
    
    # Find similar images with known descriptions
    similar = image_store.similarity_search_by_vector(
        clip.embed_image(image_path),
        k=3
    )
    
    # Use VLM for unique description, informed by similar
    similar_captions = [doc.metadata.get("caption", "") for doc in similar]
    
    prompt = f"""
Generate accessible alt-text for this image.
Consider these similar images for context: {similar_captions}

Requirements:
- Under 125 characters
- Focus on essential content
- Don't start with "Image of"
"""
    
    return vlm.invoke([HumanMessage(content=[
        {"type": "image_url", "image_url": {"url": encode(image_path)}},
        {"type": "text", "text": prompt}
    ])]).content
```

---

## Quick Reference

| Application | Key Pattern |
|-------------|-------------|
| **E-Commerce** | Image → similar products |
| **Moderation** | Image × violation embeddings |
| **Knowledge** | Unified doc + diagram search |
| **Creative** | Text + style → designs |
| **Accessibility** | Image → description |
