| **Subtopic**                                   | **Focus & Purpose**                     | **Key Concepts / Details**                                                    | **One-Line Recall**                                             |
| ---------------------------------------------- | --------------------------------------- | ----------------------------------------------------------------------------- | --------------------------------------------------------------- |
| **LC11.6.3.1 Text-to-Image Search**            | Finding images                          | Using text queries to find relevant images                                    | Text query finds matching images.                               |
| **LC11.6.3.2 Image-to-Text Search**            | Finding text                            | Using image queries to find relevant text                                     | Image query finds matching text.                                |
| **LC11.6.3.3 Image-to-Image Search**           | Visual similarity                       | Finding similar images                                                        | Find images similar to query image.                             |
| **LC11.6.3.4 Hybrid Queries**                  | Combined                                | Combining text and image in queries                                           | Combine modalities in single query.                             |
| **LC11.6.3.5 Cross-Modal Pipeline**            | End-to-end                              | Complete cross-modal search system                                            | Build end-to-end cross-modal search.                            |

# Cross-Modal Search: Finding Across Modalities

Search images with text. Search text with images.

---

## 1. Text-to-Image Search

"Find images matching this description":

```python
def text_to_image_search(query: str, k: int = 5) -> list[str]:
    """Find images matching text description."""
    results = image_store.similarity_search(query, k=k)
    
    return [doc.metadata["path"] for doc in results]

# Usage
images = text_to_image_search("a dog playing in snow")
# Returns paths to matching images
```

---

## 2. Image-to-Text Search

"Find text relevant to this image":

```python
def image_to_text_search(image_path: str, k: int = 5) -> list[str]:
    """Find text documents relevant to an image."""
    
    # Get image embedding
    image_embedding = clip.embed_image(image_path)
    
    # Search text store
    results = text_store.similarity_search_by_vector(image_embedding, k=k)
    
    return [doc.page_content for doc in results]

# Usage
relevant_texts = image_to_text_search("/photos/product.jpg")
# Returns matching product descriptions
```

---

## 3. Image-to-Image Search

"Find similar images":

```python
def image_to_image_search(query_image: str, k: int = 5) -> list[str]:
    """Find visually similar images."""
    
    # Embed query image
    query_embedding = clip.embed_image(query_image)
    
    # Search image store
    results = image_store.similarity_search_by_vector(query_embedding, k=k)
    
    # Exclude the query image itself
    return [
        doc.metadata["path"] 
        for doc in results 
        if doc.metadata["path"] != query_image
    ]

# Usage
similar = image_to_image_search("/photos/reference.jpg")
```

---

## 4. Hybrid Queries

Combine text and image context:

```python
def hybrid_search(text: str = None, image: str = None, k: int = 5):
    """Search using both text and image modalities."""
    
    embeddings = []
    
    if text:
        embeddings.append(clip.embed_query(text))
    
    if image:
        embeddings.append(clip.embed_image(image))
    
    if not embeddings:
        raise ValueError("Provide text or image")
    
    # Average embeddings
    import numpy as np
    combined = np.mean(embeddings, axis=0).tolist()
    
    return store.similarity_search_by_vector(combined, k=k)

# Usage: "Find images like this photo but with sunset"
results = hybrid_search(
    text="sunset colors",
    image="/photos/beach.jpg"
)
```

---

## 5. Complete Cross-Modal System

```python
class CrossModalSearch:
    def __init__(self):
        self.clip = OpenCLIPEmbeddings()
        self.store = Chroma(
            collection_name="multimodal",
            embedding_function=self.clip
        )
    
    def add_image(self, path: str, metadata: dict = {}):
        doc = Document(page_content="", metadata={"path": path, "type": "image", **metadata})
        self.store.add_documents([doc])
    
    def add_text(self, text: str, metadata: dict = {}):
        doc = Document(page_content=text, metadata={"type": "text", **metadata})
        self.store.add_documents([doc])
    
    def search(self, query_text: str = None, query_image: str = None, 
               return_type: str = "all", k: int = 5):
        """
        Unified search interface.
        return_type: "all", "images", "text"
        """
        # Build query embedding
        if query_text and query_image:
            emb = self._combine_embeddings(query_text, query_image)
        elif query_image:
            emb = self.clip.embed_image(query_image)
        else:
            emb = self.clip.embed_query(query_text)
        
        # Filter by type if needed
        filter_dict = None
        if return_type == "images":
            filter_dict = {"type": "image"}
        elif return_type == "text":
            filter_dict = {"type": "text"}
        
        return self.store.similarity_search_by_vector(emb, k=k, filter=filter_dict)
    
    def _combine_embeddings(self, text: str, image: str):
        import numpy as np
        t_emb = self.clip.embed_query(text)
        i_emb = self.clip.embed_image(image)
        return np.mean([t_emb, i_emb], axis=0).tolist()
```

---

## Quick Reference

| Query | Search For | Method |
|-------|------------|--------|
| Text → Images | Images matching description | `similarity_search(text)` |
| Image → Text | Text about image content | `similarity_search_by_vector(img_emb)` |
| Image → Images | Similar images | `similarity_search_by_vector(img_emb)` |
| Text+Image → Any | Combined context | Average embeddings |
