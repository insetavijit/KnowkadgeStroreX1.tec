| **Subtopic**                                   | **Focus & Purpose**                     | **Key Concepts / Details**                                                    | **One-Line Recall**                                             |
| ---------------------------------------------- | --------------------------------------- | ----------------------------------------------------------------------------- | --------------------------------------------------------------- |
| **LC11.6.4.1 Cosine Similarity**               | Metric                                  | Measuring angle-based similarity                                              | Cosine similarity is standard for CLIP.                         |
| **LC11.6.4.2 Computing Similarity**            | Implementation                          | Calculating similarity scores                                                 | Compute dot product of normalized vectors.                      |
| **LC11.6.4.3 Relevance Thresholds**            | Filtering                               | Setting cutoffs for "similar enough"                                          | 0.25+ is weak match; 0.35+ is strong match.                     |
| **LC11.6.4.4 Batch Similarity**                | Scale                                   | Comparing many pairs efficiently                                              | Use matrix multiplication for batch.                            |
| **LC11.6.4.5 Applications**                    | Use cases                               | Image-text matching, ranking, filtering                                       | Use similarity for ranking and filtering.                       |

# Image-Text Similarity: Measuring Alignment

How well does this text describe this image?

---

## 1. Cosine Similarity

CLIP embeddings are compared using cosine similarity:

```
similarity = (A · B) / (||A|| × ||B||)
```

Range: -1 to 1 (normalized CLIP vectors: 0 to 1)

---

## 2. Computing Similarity

```python
import numpy as np
from langchain_experimental.open_clip import OpenCLIPEmbeddings

clip = OpenCLIPEmbeddings()

def image_text_similarity(image_path: str, text: str) -> float:
    """Compute similarity between image and text."""
    
    # Get embeddings
    img_emb = np.array(clip.embed_image(image_path))
    txt_emb = np.array(clip.embed_query(text))
    
    # Normalize
    img_emb = img_emb / np.linalg.norm(img_emb)
    txt_emb = txt_emb / np.linalg.norm(txt_emb)
    
    # Cosine similarity
    return float(np.dot(img_emb, txt_emb))

# Usage
score = image_text_similarity("/photos/cat.jpg", "a fluffy orange cat")
print(f"Similarity: {score:.3f}")  # e.g., 0.342
```

---

## 3. Interpreting Scores

| Score | Interpretation |
|-------|----------------|
| **< 0.20** | Unrelated |
| **0.20 - 0.25** | Weak match |
| **0.25 - 0.30** | Moderate match |
| **0.30 - 0.35** | Good match |
| **> 0.35** | Strong match |

**Note**: Scores vary by domain. Calibrate for your use case.

---

## 4. Batch Similarity

Compare many pairs efficiently:

```python
def batch_similarity(image_paths: list[str], texts: list[str]) -> np.ndarray:
    """Compute similarity matrix: images × texts."""
    
    # Get all embeddings
    img_embs = np.array([clip.embed_image(p) for p in image_paths])
    txt_embs = np.array([clip.embed_query(t) for t in texts])
    
    # Normalize
    img_embs = img_embs / np.linalg.norm(img_embs, axis=1, keepdims=True)
    txt_embs = txt_embs / np.linalg.norm(txt_embs, axis=1, keepdims=True)
    
    # Matrix multiplication for all pairs
    similarity_matrix = img_embs @ txt_embs.T
    
    return similarity_matrix

# Usage
images = ["cat.jpg", "dog.jpg", "car.jpg"]
texts = ["a cute cat", "a happy dog", "a red car"]

matrix = batch_similarity(images, texts)
# matrix[i,j] = similarity between image i and text j
```

---

## 5. Applications

**Image-Caption Matching**:
```python
def find_best_caption(image: str, captions: list[str]) -> str:
    """Find the caption that best describes the image."""
    scores = [(c, image_text_similarity(image, c)) for c in captions]
    return max(scores, key=lambda x: x[1])[0]
```

**Image Filtering**:
```python
def filter_relevant_images(images: list[str], query: str, threshold: float = 0.25):
    """Keep only images matching the query."""
    return [
        img for img in images
        if image_text_similarity(img, query) >= threshold
    ]
```

**Ranking**:
```python
def rank_images_by_relevance(images: list[str], query: str) -> list[str]:
    """Rank images by relevance to query."""
    scores = [(img, image_text_similarity(img, query)) for img in images]
    ranked = sorted(scores, key=lambda x: -x[1])
    return [img for img, _ in ranked]
```

---

## Quick Reference

| Task | Approach |
|------|----------|
| **Single Pair** | `np.dot(norm(img), norm(txt))` |
| **Batch** | `img_matrix @ txt_matrix.T` |
| **Threshold** | ~0.25 for weak, ~0.35 for strong |
| **Use** | Ranking, filtering, matching |
