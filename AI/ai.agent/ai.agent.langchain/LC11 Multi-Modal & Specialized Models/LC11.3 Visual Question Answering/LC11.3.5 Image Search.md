| **Subtopic**                                   | **Focus & Purpose**                     | **Key Concepts / Details**                                                    | **One-Line Recall**                                             |
| ---------------------------------------------- | --------------------------------------- | ----------------------------------------------------------------------------- | --------------------------------------------------------------- |
| **LC11.3.5.1 Semantic Image Search**           | Concept search                          | Finding images by meaning, not keywords                                       | Semantic search finds visually similar images.                  |
| **LC11.3.5.2 Image Embedding Models**          | Encoders                                | CLIP, SigLIP, OpenCLIP for visual embeddings                                  | Use CLIP-like models for image embeddings.                      |
| **LC11.3.5.3 Vector Store for Images**         | Storage                                 | Indexing and searching image embeddings                                       | Store image vectors in Chroma, Pinecone, etc.                   |
| **LC11.3.5.4 Similarity Metrics**              | Distance                                | Cosine similarity, L2 distance for images                                     | Cosine similarity works well for CLIP vectors.                  |
| **LC11.3.5.5 Image Search Pipeline**           | End-to-end                              | Complete image search implementation                                          | Build end-to-end image search with LangChain.                   |

# Image Search: Finding Visual Content

Search images by what they LOOK like, not their filenames.

---

## 1. Semantic Image Search

**Traditional Search**: Search by filename, tags, metadata
**Semantic Search**: Search by visual content and meaning

```
Query: "sunset over water"
Returns: Images of ocean sunsets, lake reflections, etc.
(Without those exact words in metadata)
```

---

## 2. Image Embedding Models

| Model | Source | Notes |
|-------|--------|-------|
| **CLIP** | OpenAI | Most popular, balanced |
| **OpenCLIP** | LAION | Open-source variants |
| **SigLIP** | Google | Better for some tasks |
| **BLIP** | Salesforce | Good for captioning |

**LangChain Setup**:
```python
from langchain_experimental.open_clip import OpenCLIPEmbeddings

clip = OpenCLIPEmbeddings(
    model_name="ViT-B-32",
    checkpoint="openai"
)
```

---

## 3. Vector Store for Images

```python
from langchain_chroma import Chroma
from langchain_core.documents import Document

# Create image documents
image_docs = []
for path in image_paths:
    # Store path in metadata, leave content empty for images
    doc = Document(
        page_content="",  # Images don't have text content
        metadata={"path": path, "filename": os.path.basename(path)}
    )
    image_docs.append(doc)

# Create vector store
image_store = Chroma.from_documents(
    documents=image_docs,
    embedding=clip,
    collection_name="image_search"
)
```

**Note**: OpenCLIP embeddings handle image paths automatically.

---

## 4. Search Implementation

**Text-to-Image Search**:
```python
# Find images matching text query
results = image_store.similarity_search(
    query="a person riding a bicycle",
    k=5
)

for doc in results:
    print(doc.metadata["path"])
```

**Image-to-Image Search**:
```python
# Find similar images
query_embedding = clip.embed_image("/path/to/query.jpg")

results = image_store.similarity_search_by_vector(
    embedding=query_embedding,
    k=5
)
```

---

## 5. Complete Image Search Pipeline

```python
class ImageSearchEngine:
    def __init__(self, persist_dir: str = "./image_index"):
        self.embeddings = OpenCLIPEmbeddings()
        self.vectorstore = Chroma(
            collection_name="images",
            embedding_function=self.embeddings,
            persist_directory=persist_dir
        )
    
    def index_images(self, image_paths: list[str]):
        """Add images to the search index."""
        docs = [
            Document(page_content="", metadata={"path": p})
            for p in image_paths
        ]
        self.vectorstore.add_documents(docs)
    
    def search_by_text(self, query: str, k: int = 5) -> list[str]:
        """Find images matching text description."""
        results = self.vectorstore.similarity_search(query, k=k)
        return [doc.metadata["path"] for doc in results]
    
    def search_by_image(self, image_path: str, k: int = 5) -> list[str]:
        """Find images similar to given image."""
        embedding = self.embeddings.embed_image(image_path)
        results = self.vectorstore.similarity_search_by_vector(embedding, k=k)
        return [doc.metadata["path"] for doc in results]

# Usage
engine = ImageSearchEngine()
engine.index_images(glob.glob("./photos/*.jpg"))
results = engine.search_by_text("beach vacation")
```

---

## Quick Reference

| Search Type | Method |
|-------------|--------|
| **Text → Image** | `similarity_search(text)` |
| **Image → Image** | `similarity_search_by_vector(embed_image())` |
| **Hybrid** | Combine with metadata filtering |
