| **Subtopic**                                   | **Focus & Purpose**                     | **Key Concepts / Details**                                                    | **One-Line Recall**                                             |
| ---------------------------------------------- | --------------------------------------- | ----------------------------------------------------------------------------- | --------------------------------------------------------------- |
| **LC11.3.4.1 What is Multi-Modal RAG?**        | Definition                              | RAG with both text and image retrieval                                        | Multi-modal RAG retrieves text AND images as context.           |
| **LC11.3.4.2 Image as Context**                | Usage pattern                           | Retrieving images to provide visual context                                   | Retrieved images become part of VLM context.                    |
| **LC11.3.4.3 Mixed Document Types**            | Hybrid                                  | PDFs with images, slides, diagrams                                            | Handle documents that mix text and visuals.                     |
| **LC11.3.4.4 Architecture Patterns**           | Design                                  | Retrieve → Process → Generate with images                                     | Separate retrieval for text and images.                         |
| **LC11.3.4.5 Production Considerations**       | Scale                                   | Costs, latency, caching for multi-modal                                       | Multi-modal RAG is more expensive than text-only.               |

# Multi-Modal RAG: Beyond Text-Only Retrieval

Traditional RAG retrieves text. Multi-Modal RAG retrieves images too.

---

## 1. What is Multi-Modal RAG?

```
Query → Retrieve (Text + Images) → VLM → Answer
```

**Use Case**: "Show me the architecture diagram for our payment system"
*   Retrieves both documentation text AND the actual diagram image
*   VLM sees both and generates comprehensive answer

---

## 2. Image as Context

Retrieved images become part of the prompt:

```python
# Retrieve relevant images
image_docs = image_vectorstore.similarity_search(query, k=3)

# Retrieve relevant text
text_docs = text_vectorstore.similarity_search(query, k=5)

# Build multi-modal message
content = [
    {"type": "text", "text": f"Context documents:\n{format_docs(text_docs)}"},
]

# Add retrieved images
for doc in image_docs:
    content.append({
        "type": "image_url",
        "image_url": {"url": doc.metadata["image_url"]}
    })

content.append({"type": "text", "text": f"Question: {query}"})

response = vlm.invoke([HumanMessage(content=content)])
```

---

## 3. Mixed Document Types

Many documents contain both text and images:
*   PDF reports with charts
*   Slides with diagrams
*   Technical docs with screenshots

**Approach**:
```python
# 1. Extract text from document
text_chunks = text_splitter.split_documents(loader.load())

# 2. Extract images from document
images = extract_images_from_pdf(pdf_path)

# 3. Index both in linked stores
for i, chunk in enumerate(text_chunks):
    chunk.metadata["related_images"] = find_related_images(chunk, images)
```

---

## 4. Architecture Patterns

**Pattern A: Parallel Retrieval**
```
Query ─┬─→ Text Store ───→ Text Docs ─┐
       │                               ├─→ VLM → Answer
       └─→ Image Store ──→ Images ────┘
```

**Pattern B: Sequential (Image-aware)**
```
Query → Text Store → Text Docs → Extract Image Refs → Fetch Images → VLM
```

**Pattern C: Unified Store**
```
Query → Multi-Modal Store (CLIP) → Mixed Results → VLM
```

---

## 5. Production Considerations

| Factor | Challenge | Mitigation |
|--------|-----------|------------|
| **Cost** | Images = more tokens | Limit to 2-3 images |
| **Latency** | Multiple retrievals | Parallel fetching |
| **Relevance** | Image vs text ranking | Weighted combination |
| **Storage** | Image embeddings large | Compression, tiers |

**Cost Estimate**:
*   Text-only RAG: ~$0.01 per query
*   Multi-modal RAG: ~$0.05-0.10 per query (with 3 images)

---

## Quick Reference

| Component | Tool Choice |
|-----------|-------------|
| **Text Embeddings** | OpenAI, Cohere |
| **Image Embeddings** | CLIP, SigLIP |
| **Vector Store** | Chroma, Pinecone, Weaviate |
| **VLM** | GPT-4o, Claude 3, Gemini |
