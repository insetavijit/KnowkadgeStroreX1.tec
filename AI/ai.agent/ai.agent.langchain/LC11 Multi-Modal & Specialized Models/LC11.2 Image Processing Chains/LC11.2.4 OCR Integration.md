| **Subtopic**                                   | **Focus & Purpose**                     | **Key Concepts / Details**                                                    | **One-Line Recall**                                             |
| ---------------------------------------------- | --------------------------------------- | ----------------------------------------------------------------------------- | --------------------------------------------------------------- |
| **LC11.2.4.1 VLM-Based OCR**                   | Built-in                                | Using VLMs for text extraction                                                | VLMs can read text in images natively.                          |
| **LC11.2.4.2 Dedicated OCR Services**          | Specialized                             | Tesseract, AWS Textract, Google Vision                                        | Dedicated OCR is better for complex documents.                  |
| **LC11.2.4.3 Document Text Extraction**        | Documents                               | Extracting text from PDFs, scans                                              | Use OCR for scanned documents.                                  |
| **LC11.2.4.4 Handwriting Recognition**         | Cursive                                 | Reading handwritten text                                                      | VLMs struggle with cursive; use specialized tools.              |
| **LC11.2.4.5 OCR + LLM Pipeline**              | Integration                             | OCR extraction → LLM processing                                               | Extract text with OCR, then process with LLM.                   |

# OCR Integration: Reading Text in Images

OCR (Optical Character Recognition) extracts text from images.

---

## 1. VLM-Based OCR (Simple)

VLMs like GPT-4o can read text in images:

```python
message = HumanMessage(
    content=[
        {"type": "text", "text": "Extract all text visible in this image."},
        {"type": "image_url", "image_url": {"url": document_url}}
    ]
)

text = llm.invoke([message]).content
```

**Pros**: No extra setup, handles context naturally.
**Cons**: Less accurate for dense text, costs more tokens.

---

## 2. Dedicated OCR Services

| Service | Strengths |
|---------|-----------|
| **Tesseract** | Free, local, good for simple documents |
| **AWS Textract** | Tables, forms, handwriting |
| **Google Vision** | Multi-language, fast |
| **Azure Doc Intelligence** | Complex layouts |

**Tesseract Example**:
```python
import pytesseract
from PIL import Image

def extract_text_tesseract(image_path: str) -> str:
    img = Image.open(image_path)
    return pytesseract.image_to_string(img)
```

---

## 3. Document Text Extraction

For scanned PDFs:

```python
import pdf2image
import pytesseract

def extract_pdf_text(pdf_path: str) -> str:
    """Extract text from scanned PDF using OCR."""
    pages = pdf2image.convert_from_path(pdf_path)
    
    full_text = []
    for page in pages:
        text = pytesseract.image_to_string(page)
        full_text.append(text)
    
    return "\n\n".join(full_text)
```

---

## 4. Handwriting Challenges

Handwritten text is hard for standard OCR.

| Text Type | Best Approach |
|-----------|---------------|
| **Printed** | Tesseract, VLM |
| **Block Letters** | VLM usually works |
| **Cursive** | Specialized models (AWS Textract) |
| **Messy** | Human fallback |

**VLM Prompt for Handwriting**:
```python
"This image contains handwritten text. Read it carefully and transcribe exactly what you see, noting any unclear words."
```

---

## 5. OCR + LLM Pipeline

**Pattern**: OCR extracts raw text → LLM structures/processes it.

```python
# Step 1: OCR extraction
raw_text = pytesseract.image_to_string(document_image)

# Step 2: LLM processing
prompt = ChatPromptTemplate.from_template("""
Extract the following fields from this receipt text:
- Store name
- Date
- Total amount

Receipt text:
{raw_text}
""")

chain = prompt | llm | JsonOutputParser()
result = chain.invoke({"raw_text": raw_text})
```

**Why this pattern?**:
*   OCR is cheap/fast for text extraction
*   LLM handles understanding and structuring
*   More cost-effective than sending images to VLM

---

## Quick Reference

| Approach | When to Use |
|----------|-------------|
| **VLM OCR** | Simple images, need context |
| **Tesseract** | Bulk processing, cost-sensitive |
| **Cloud OCR** | Complex layouts, accuracy critical |
| **OCR + LLM** | Structured extraction at scale |
