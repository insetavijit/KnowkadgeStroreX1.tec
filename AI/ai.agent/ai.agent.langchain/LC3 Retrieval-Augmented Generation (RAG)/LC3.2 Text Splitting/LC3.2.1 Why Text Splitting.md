| **Subtopic**                                          | **Focus & Purpose**                          | **Key Concepts / Details**                                                      | **One-Line Recall**                                                 |
| ----------------------------------------------------- | -------------------------------------------- | ------------------------------------------------------------------------------- | ------------------------------------------------------------------- |
| **[[LC3.2.1.1 Chunk Size Limits]]**                   | Understand size constraints                  | Embedding model limits, context window size, token limits                       | Chunks must fit within embedding and context limits.                |
| **[[LC3.2.1.2 Context Window Constraints]]**          | Work within LLM limits                       | Max tokens, prompt + context budget, fitting retrieved docs                     | Chunks must fit in LLM context with prompt.                         |
| **[[LC3.2.1.3 Retrieval Granularity]]**               | Balance precision and recall                 | Too large (noisy), too small (fragmented), optimal granularity                  | Chunk size affects retrieval precision and recall.                  |
| **[[LC3.2.1.4 Embedding Quality]]**                   | Optimize for semantic search                 | Coherent chunks, semantic meaning, embedding effectiveness                      | Coherent chunks produce better embeddings.                          |
| **[[LC3.2.1.5 Splitting Motivation]]**                | Know when and why to split                   | Large documents, retrieval needs, efficient processing                          | Split documents for effective RAG retrieval.                        |
