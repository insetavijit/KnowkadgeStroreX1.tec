| **Subtopic**                                          | **Focus & Purpose**                          | **Key Concepts / Details**                                                      | **One-Line Recall**                                                 |
| ----------------------------------------------------- | -------------------------------------------- | ------------------------------------------------------------------------------- | ------------------------------------------------------------------- |
| **[[LC9.5.4.1 OPRO]]**                                | Optimization by PROmpting                    | Google DeepMind method; LLM iteratively improving instructions based on score   | Let LLM interactively improve prompts.                              |
| **[[LC9.5.4.2 Genetic Algorithms]]**                  | Evolution                                    | Mutating prompts; crossing over best performers; selecting fittest candidates   | Evolve prompts genetically.                                         |
| **[[LC9.5.4.3 Gradient Descent]]**                    | Soft prompts                                 | Continuous embedding optimization (if access allows); rare in API usage         | Optimize soft prompts if possible.                                  |
| **[[LC9.5.4.4 Feedback Integration]]**                | Learning from data                           | Using failure cases to explicitly request 'better instructions' from optimizer  | Integrate feedback into optimization.                               |
| **[[LC9.5.4.5 Cost/Benefit]]**                        | Trade-offs                                   | Token cost of optimization runs vs performance gain                             | Weigh cost of automated optimization.                               |
