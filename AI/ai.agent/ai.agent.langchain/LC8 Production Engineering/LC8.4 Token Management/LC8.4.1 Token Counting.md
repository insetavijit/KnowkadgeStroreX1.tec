| **Subtopic**                                          | **Focus & Purpose**                          | **Key Concepts / Details**                                                      | **One-Line Recall**                                                 |
| ----------------------------------------------------- | -------------------------------------------- | ------------------------------------------------------------------------------- | ------------------------------------------------------------------- |
| **[[LC8.4.1.1 Tiktoken Usage]]**                      | Reference tokenizer implementation           | tiktoken library; encoding for specific models (cl100k_base); byte pair encoding| Use tiktoken to count OpenAI tokens.                                |
| **[[LC8.4.1.2 Provider Specifics]]**                  | Variations across models                     | Anthropic vs OpenAI vs Llama counting rules; handling special tokens            | Account for different tokenizer rules.                              |
| **[[LC8.4.1.3 Chain Token Counting]]**                | Counting across workflows                    | get_openai_callback; measuring total chain usage; overhead estimation           | Track tokens for entire chains.                                     |
| **[[LC8.4.1.4 Prompt Token Calculation]]**            | Estimating before sending                    | Pre-flight checks; estimating input costs; formatting overhead                  | Estimate cost before execution.                                     |
| **[[LC8.4.1.5 Response Token Parsing]]**              | Reading usage from response                  | token_usage in API responses; parsing completion_tokens and prompt_tokens       | Read usage stats from API result.                                   |
