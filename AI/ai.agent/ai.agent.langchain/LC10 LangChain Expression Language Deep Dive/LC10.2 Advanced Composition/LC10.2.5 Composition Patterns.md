| **Subtopic**                                   | **Focus & Purpose**                     | **Key Concepts / Details**                                                    | **One-Line Recall**                                             |
| ---------------------------------------------- | --------------------------------------- | ----------------------------------------------------------------------------- | --------------------------------------------------------------- |
| **LC10.2.5.1 The RAG Pattern**                 | Standard Retrieval Augmented Gen        | Parallel retrieving + passthrough → Prompt → LLM                              | {context, question} \| prompt \| llm is the standard RAG shape. |
| **LC10.2.5.2 The Branching Pattern**           | Conditional Logic                       | RunnableBranch, conditional routing based on input                            | Route to different chains based on input criteria.              |
| **LC10.2.5.3 The Map-Reduce Pattern**          | Processing lists                        | .map(), batch processing items and summarizing results                        | Map input list to sub-chains, then reduce the results.          |
| **LC10.2.5.4 The Self-Correction Pattern**     | Loops and Validation                    | Check output → if bad, retry (requires graph or recursion)                    | Validate output and re-run if criteria aren't met.              |
| **LC10.2.5.5 The History Injection Pattern**   | Memory integration                      | Inserting chat history into parallel context block                            | Inject chat_history alongside questions in the prompt input.    |

# Composition Patterns: The Architectural Cookbook

Just as software engineering has "Design Patterns" (Singleton, Factory, Observer), LCEL has **Composition Patterns**. These are standard structural recipes for solving common AI problems. Memorizing these shapes allows you to "speak" LCEL fluently.

---

## 1. The RAG Pattern (The "H")

 The most common pattern. It looks like the letter "H" sideways: Input splits into Context and Question, then joins at the Prompt.

```python
rag_chain = (
    {"context": retriever, "question": RunnablePassthrough()} 
    | prompt 
    | llm 
    | parser
)
```

1.  **Split**: Input question goes to Retriever AND keeps going as "question".
2.  **Join**: Results merge into a dictionary.
3.  **Process**: Dictionary feeds the prompt.

---

## 2. The Branching Pattern (The Router)

"If X, do A. Else, do B."

```python
from langchain_core.runnables import RunnableBranch

branch = RunnableBranch(
    (lambda x: "math" in x["topic"].lower(), math_chain),
    (lambda x: "history" in x["topic"].lower(), history_chain),
    general_chain  # Default branch
)

full_chain = classification_step | branch
```

Use this for **Semantic Routing**: Ask an LLM to classify the intent, then route to a specialized chain.

---

## 3. The Map-Reduce Pattern (The List Processor)

"I have 10 documents. Summarize each one, then summarize the summaries."

```python
# Step 1: Same chain applied to LIST of inputs
map_chain = summary_chain.map()

# Step 2: Combine results
reduce_chain = (
    map_chain                  # Returns List[str]
    | (lambda x: "\n".join(x)) # Joins into one string
    | final_summary_chain      # Summarizes the big string
)

reduce_chain.invoke([doc1, doc2, doc3, ...])
```

The `.map()` method automatically handles iterating over the input list and running the Runnable for each item.

---

## 4. The History Injection Pattern (The Chatbot)

Incorporating memory into RAG.

```python
chain = (
    RunnablePassthrough.assign(
        chat_history=lambda x: x["chat_history"]  # Pass history through
    )
    | context_retrieval_branch  # Uses question to find docs
    | prompt                    # Prompt uses {context}, {question}, {chat_history}
    | llm
)
```

This pattern ensures that `chat_history` is available at the prompt stage without interfering with the retrieval stage.

---

## 5. The Fallback Pattern (The Safety Net)

"Try the big model. If it errors (or finds nothing), try the cheap/simple one."

```python
chain = (
    gpt4_chain.with_fallbacks([gpt35_chain, heuristic_chain])
)
```

Use this for high-reliability systems where uptime is critical.

---

## 6. Visualizing the Patterns

It helps to draw these on a whiteboard.

*   **RAG**: Parallel fork -> Merge.
*   **Router**: 1-to-N switch.
*   **Map**: 1 list -> N parallel executions -> 1 list.
*   **Fallback**: Stack of layers (Try layer 1, drop to layer 2).

---

## Quick Reference

| Pattern | Structure | Use Case |
|---------|-----------|----------|
| **RAG** | `Parallel({ctx, q}) \| Prompt` | QA on custom data |
| **Branch** | `RunnableBranch((cond, chain), default)` | Conditional logic |
| **Map** | `chain.map()` | Processing lists of items |
| **Injection** | `Passthrough.assign()` | Adding data to the stream |
| **Fallback** | `chain.with_fallbacks()` | Error recovery |
