| **Subtopic**                                   | **Focus & Purpose**                     | **Key Concepts / Details**                                                    | **One-Line Recall**                                             |
| ---------------------------------------------- | --------------------------------------- | ----------------------------------------------------------------------------- | --------------------------------------------------------------- |
| **LC10.1.5.1 Generic Type Parameters**         | Understand Runnable typing              | Runnable[Input, Output], generic protocol, type variables                     | Runnable is generic over InputType and OutputType.              |
| **LC10.1.5.2 Type Inference**                  | How types flow through chains           | Automatic inference, pipe operator typing, IDE support                        | LCEL infers types through the chain automatically.              |
| **LC10.1.5.3 Runtime Type Checking**           | Validate types at execution             | Pydantic validation, TypedDict, input validation                              | Use Pydantic models for runtime type safety.                    |
| **LC10.1.5.4 Type Annotations in Custom Code** | Define types for custom Runnables       | Type hints, Protocol implementation, explicit annotations                     | Always annotate InputType and OutputType in custom Runnables.   |
| **LC10.1.5.5 Common Type Patterns**            | Recognize typical type signatures       | Dict → str, Message → Message, Any → structured                               | Learn common patterns: prompts take dicts, models return messages.|

# InputType & OutputType: The Type Contract

Every Runnable declares its **type contract**: what it accepts (InputType) and what it returns (OutputType). This isn't just documentation—it enables IDE autocompletion, static analysis, and catches composition errors before runtime.

---

## 1. The Generic Protocol: Runnable[Input, Output]

Runnable is a **generic class** parameterized over two types:

```python
from langchain_core.runnables import Runnable

class MyRunnable(Runnable[str, int]):
    """Accepts string, returns integer."""
    
    def invoke(self, input: str) -> int:
        return len(input)
```

```
┌─────────────────────────────────────────────────┐
│            Runnable[InputType, OutputType]      │
├─────────────────────────────────────────────────┤
│  InputType   →  What invoke() accepts           │
│  OutputType  →  What invoke() returns           │
└─────────────────────────────────────────────────┘
```

**Key Insight**: When composing with `|`, the OutputType of one Runnable must be compatible with the InputType of the next.

---

## 2. Type Inference Through Chains

LCEL automatically infers types as data flows through the pipe:

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

# Type flow:
#   dict → ChatPromptValue → AIMessage → str
chain = (
    ChatPromptTemplate.from_template("Explain {topic}")  # dict → ChatPromptValue
    | ChatOpenAI()                                        # ChatPromptValue → AIMessage
    | StrOutputParser()                                   # AIMessage → str
)

# IDE knows: chain.invoke() expects dict, returns str
result: str = chain.invoke({"topic": "types"})
```

### IDE Support

Modern IDEs (VS Code, PyCharm) leverage these types to provide:
*   Autocompletion for input keys
*   Type error warnings before runtime
*   Documentation on hover

---

## 3. Runtime Type Checking with Pydantic

For production systems, enforce types at runtime using Pydantic models:

```python
from pydantic import BaseModel
from langchain_core.runnables import RunnableLambda

class QueryInput(BaseModel):
    question: str
    max_tokens: int = 100

class QueryOutput(BaseModel):
    answer: str
    confidence: float

def process(input: QueryInput) -> QueryOutput:
    # Your logic here
    return QueryOutput(answer="...", confidence=0.95)

# Pydantic validates at runtime
runnable = RunnableLambda(process)
result = runnable.invoke(QueryInput(question="What is AI?"))
```

### Why Runtime Validation Matters

*   **Fail Fast**: Invalid data caught immediately, not deep in the chain
*   **Clear Errors**: Pydantic provides detailed validation messages
*   **Documentation**: Schema doubles as API documentation

---

## 4. Type Annotations in Custom Runnables

When building custom Runnables, always specify types explicitly:

```python
from langchain_core.runnables import RunnableLambda
from typing import TypedDict

class SearchInput(TypedDict):
    query: str
    limit: int

class SearchResult(TypedDict):
    title: str
    url: str
    score: float

def search(input: SearchInput) -> list[SearchResult]:
    # Perform search
    return [{"title": "...", "url": "...", "score": 0.9}]

# Type-safe custom runnable
search_runnable: Runnable[SearchInput, list[SearchResult]] = RunnableLambda(search)
```

### Accessing Type Information

```python
# Inspect a Runnable's types
print(chain.InputType)   # Shows expected input type
print(chain.OutputType)  # Shows expected output type
```

---

## 5. Common Type Patterns

Memorize these patterns—they cover 90% of LCEL usage:

| Component | InputType | OutputType |
|-----------|-----------|------------|
| `ChatPromptTemplate` | `dict` | `ChatPromptValue` |
| `ChatOpenAI` | `PromptValue`, `str`, `List[Message]` | `AIMessage` |
| `StrOutputParser` | `AIMessage` | `str` |
| `JsonOutputParser` | `AIMessage` | `dict` |
| `PydanticOutputParser[T]` | `AIMessage` | `T` |
| `RunnablePassthrough` | `Any` | `Any` (same as input) |
| `RunnableLambda` | `Any` | `Any` (you define) |

### The "dict → str" Pipeline

The most common pattern: dictionary input (template variables) → string output (parsed response).

```python
# dict → ... → str
chain = prompt | llm | StrOutputParser()
result: str = chain.invoke({"topic": "AI"})
```

---

## 6. Type Mismatches: Debugging Composition Errors

When types don't align, you get runtime errors. Learn to read them:

```python
# ❌ This will fail at runtime
chain = StrOutputParser() | ChatOpenAI()
# Error: ChatOpenAI expects PromptValue or str, got str from incorrect position

# ✅ Correct order: prompt → model → parser
chain = ChatPromptTemplate.from_template("{x}") | ChatOpenAI() | StrOutputParser()
```

### Debugging Checklist

1. Check `OutputType` of component N
2. Check `InputType` of component N+1
3. Ensure compatibility (exact match or coercion)

---

## Quick Reference

| Concept | Key Point |
|---------|-----------|
| **Runnable[In, Out]** | Generic over InputType and OutputType |
| **Type Inference** | Automatic through pipe operator |
| **Pydantic** | Runtime validation for production safety |
| **TypedDict** | Lightweight type hints for dict shapes |
| **InputType/OutputType** | Accessible via `.InputType`, `.OutputType` |
| **Common Pattern** | dict → ChatPromptValue → AIMessage → str |
| **Benefit** | **Safety**: Catch errors before runtime, enable IDE support |
