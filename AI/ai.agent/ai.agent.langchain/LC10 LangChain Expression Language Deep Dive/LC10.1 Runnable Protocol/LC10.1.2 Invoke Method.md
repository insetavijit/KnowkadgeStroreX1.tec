| **Subtopic**                                   | **Focus & Purpose**                     | **Key Concepts / Details**                                                    | **One-Line Recall**                                             |
| ---------------------------------------------- | --------------------------------------- | ----------------------------------------------------------------------------- | --------------------------------------------------------------- |
| **LC10.1.2.1 Invoke Semantics**                | Define invoke() behavior                | Single input, single output, synchronous execution                            | invoke() processes one input and returns one output.            |
| **LC10.1.2.2 Input Types**                     | Understand valid inputs                 | Dict, str, PromptValue, BaseMessage; type coercion                            | Runnables accept various input types based on implementation.   |
| **LC10.1.2.3 Return Values**                   | Understand output structure             | OutputType guarantee, AIMessage, str, structured data                         | invoke() returns the Runnable's declared OutputType.            |
| **LC10.1.2.4 Config Parameter**                | Control execution context               | RunnableConfig, callbacks, tags, metadata, run_name                           | Config customizes tracing, callbacks, and runtime behavior.     |
| **LC10.1.2.5 Error Handling**                  | Handle invocation failures              | Exception propagation, retry patterns, graceful degradation                   | Errors in invoke() propagate unless explicitly handled.         |

# The Invoke Method: Synchronous Execution Foundation

The `invoke()` method is the **heartbeat of LCEL**. It's the simplest, most direct way to execute a Runnable—send one input, receive one output. Every chain you build ultimately calls `invoke()` under the hood, making it the method you must understand first.

---

## 1. The Fundamental Contract: One In, One Out

`invoke()` is **deterministic in shape**: you pass a single input, you get a single output.

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI()
result = llm.invoke("What is the capital of France?")
# result: AIMessage(content="The capital of France is Paris.")
```

This simplicity is intentional. Unlike `batch()` or `stream()`, there's no concurrency, no iteration—just a clean function call.

**Key Insight**: Master `invoke()` first. Every other method (`batch`, `stream`) builds on this mental model.

---

## 2. Input Type Flexibility

Different Runnables accept different input types. Understanding this prevents runtime errors.

```
┌──────────────────────────────────────────────────┐
│              Common Input Types                  │
├──────────────────────────────────────────────────┤
│  ChatPromptTemplate  →  dict (template vars)     │
│  ChatOpenAI          →  str, List[BaseMessage]   │
│  StrOutputParser     →  AIMessage, ChatResult    │
│  RunnableLambda      →  Any (you define it)      │
└──────────────────────────────────────────────────┘
```

### Example: Same Model, Different Inputs

```python
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

llm = ChatOpenAI()

# String input (auto-wrapped as HumanMessage)
result1 = llm.invoke("Hello")

# Message list input (explicit control)
result2 = llm.invoke([
    SystemMessage(content="You are a pirate."),
    HumanMessage(content="Hello")
])
```

---

## 3. Return Values: The OutputType Guarantee

Every Runnable declares what it returns. This is codified as `OutputType`.

| Runnable | OutputType |
|----------|------------|
| `ChatOpenAI` | `AIMessage` |
| `StrOutputParser` | `str` |
| `JsonOutputParser` | `dict` |
| `PydanticOutputParser` | Your Pydantic model |

```python
from langchain_core.output_parsers import StrOutputParser

parser = StrOutputParser()
# Input: AIMessage, Output: str (the content extracted)
text = parser.invoke(result)
```

**Why This Matters**: When composing chains with `|`, the OutputType of one Runnable must match the InputType of the next.

---

## 4. The Config Parameter: Runtime Customization

`invoke()` accepts an optional `config` parameter for execution control.

```python
from langchain_core.runnables import RunnableConfig

config = RunnableConfig(
    tags=["production", "user-123"],
    metadata={"request_id": "abc-123"},
    run_name="Capital Query",
    callbacks=[my_callback_handler]
)

result = llm.invoke("What is the capital of Japan?", config=config)
```

### Common Config Options

| Option | Purpose |
|--------|---------|
| `tags` | Labels for filtering in LangSmith |
| `metadata` | Arbitrary key-value pairs for tracing |
| `run_name` | Human-readable name in trace logs |
| `callbacks` | Custom handlers for events |
| `max_concurrency` | Limit parallel execution (for batch) |

---

## 5. Error Handling: Fail Fast or Recover

By default, `invoke()` propagates exceptions. You must handle them explicitly.

```python
from langchain_core.runnables import RunnableWithFallbacks

# Primary chain with fallback
chain_with_fallback = primary_llm.with_fallbacks([backup_llm])

try:
    result = chain_with_fallback.invoke("Query")
except Exception as e:
    # Handle complete failure
    log_error(e)
```

### Common Exception Patterns

*   **API Errors**: Rate limits, authentication failures
*   **Timeout**: Model takes too long to respond
*   **Validation**: Input doesn't match expected type
*   **Parsing**: Output doesn't match expected format

---

## 6. Invoke in Chains: How Composition Works

When you use the pipe operator `|`, you're connecting `invoke()` calls:

```python
chain = prompt | llm | parser

# This is equivalent to:
# parser.invoke(llm.invoke(prompt.invoke(input)))

result = chain.invoke({"topic": "LCEL"})
```

The chain's `invoke()` orchestrates the cascade—each component's output feeds the next component's input.

---

## Quick Reference

| Concept | Key Point |
|---------|-----------|
| **invoke()** | Synchronous, single input → single output |
| **Input Types** | Varies by Runnable (dict, str, Message) |
| **OutputType** | Guaranteed return type for each Runnable |
| **Config** | Optional runtime customization (tags, callbacks) |
| **Error Handling** | Exceptions propagate; use fallbacks for recovery |
| **In Chains** | Each `invoke()` output feeds the next input |
| **Benefit** | **Simplicity**: The clearest way to execute any Runnable |
