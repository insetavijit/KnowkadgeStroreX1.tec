| **Subtopic**                                   | **Focus & Purpose**                     | **Key Concepts / Details**                                                    | **One-Line Recall**                                             |
| ---------------------------------------------- | --------------------------------------- | ----------------------------------------------------------------------------- | --------------------------------------------------------------- |
| **LC10.6.5.1 The "Generative UI"**             | Pattern                                 | Streaming component names + props to render UI dynamically                    | Stream structured data to drive dynamic UI components.            |
| **LC10.6.5.2 The "Thinking" Stream**           | UX Pattern                              | Streaming internal reasoning (COT) separate from final answer                 | Stream 'thought' tokens to a side-panel, answer to main.        |
| **LC10.6.5.3 The "Multi-Modal" Stream**        | Mixed Media                             | Streaming text alongside image URLs or references                             | Stream mix of text and reference pointers.                      |
| **LC10.6.5.4 Server-Sent Events (SSE)**        | Transport                               | Standard protocol for pushing event streams to browser                        | Use SSE to transport astream_events to the web client.          |
| **LC10.6.5.5 The Buffered Stream**             | User Experience                         | Waiting for newlines or sentences before updating UI to reduce flicker        | Buffer tokens to update UI in meaningful chunks (words/lines).  |

# Streaming Patterns: UX Best Practices

Streaming isn't just about printing characters fast. It's about communicating **progress** and **intent**.

---

## 1. The "Thinking" Stream (Chain of Thought)

For RAG or Agents, users want to know *what* is happening, but they don't want the prompt in their face.

**Strategy**:
1.  Tag the "Reasoning" steps with `["thought"]`.
2.  Tag the "Final Answer" steps with `["answer"]`.
3.  In UI: Render "thoughts" in a collapsible `<details>` block, render "answer" in the main chat bubble.

This builds trust without clutter.

---

## 2. Generative UI (Streaming Components)

Instead of streaming text, stream **JSON** that represents UI config.

```json
// Stream 1
{"component": "Chart", "props": {"data": [10, 20...]} }
```

As the JSON object completes, the client renders the React component. `JsonOutputParser` facilitates this by yielding partial valid structures.

---

## 3. Server-Sent Events (SSE)

The industry standard for AI streaming.

**Python (FastAPI)**:
```python
from fastapi import FastAPI
from langchain_core.runnables import Runnable

app = FastAPI()

@app.get("/stream")
async def stream(query: str):
    async def event_generator():
        async for event in chain.astream_events(query, version="v2"):
            yield f"data: {json.dumps(event)}\n\n"
    
    return StreamingResponse(event_generator(), media_type="text/event-stream")
```

**Client (JS)**:
```javascript
const eventSource = new EventSource("/stream?query=...");
eventSource.onmessage = (e) => {
    const event = JSON.parse(e.data);
    // update UI
};
```

---

## 4. The Buffered Stream (Anti-Flicker)

Rendering every single character can cause high CPU load and visual jitter.

**Pattern**: Accumulate tokens until a space (` `) or newline (`\n`) appears, then flush to UI. This feels smoother to the human eyeâ€”like words appearing at once.

---

## Quick Reference

| Pattern | Usage |
|---------|-------|
| **Thinking** | Separate reasoning from answer |
| **GenUI** | Stream UI config, not just text |
| **SSE** | The transport protocol |
| **Buffering** | UX optimization |
