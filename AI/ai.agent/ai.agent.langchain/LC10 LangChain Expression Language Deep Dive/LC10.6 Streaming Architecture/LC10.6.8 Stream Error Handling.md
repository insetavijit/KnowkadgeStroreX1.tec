| **Subtopic**                                   | **Focus & Purpose**                     | **Key Concepts / Details**                                                    | **One-Line Recall**                                             |
| ---------------------------------------------- | --------------------------------------- | ----------------------------------------------------------------------------- | --------------------------------------------------------------- |
| **LC10.6.8.1 Stream Interruptions**            | Failure modes                           | Network cut, API error mid-stream                                             | Streams can die in the middle; handle the exception.            |
| **LC10.6.8.2 Yielding Errors**                 | UX Pattern                              | Sending a special "Error Chunk" to the UI instead of crashing                 | Don't crash the UI; stream an error message to the user.        |
| **LC10.6.8.3 Resuming Streams**                | Advanced                                | Retrying from the last successful chunk (very hard with LLMs)                 | Resuming LLM streams is difficult; usually restart.             |
| **LC10.6.8.4 Timeout Handling**                | Latency                                 | Killing a stream if a chunk takes too long                                    | Set timeouts for individual chunks to prevent hanging.          |
| **LC10.6.8.5 Fallback Streams**                | Recovery                                | Switching to a backup stream on error                                         | Switch generator sources if one fails.                          |

# Stream Error Handling: When the Pipe Bursts

In a normal function, you get a return value OR an exception.
In a stream, you might get 50% of the return value AND THEN an exception.

---

## 1. Stream Interruptions

```python
async def risky_stream():
    yield "Start"
    yield "Middle"
    raise Exception("Boom")

# Consumer
try:
    async for chunk in risky_stream():
        print(chunk)
except Exception:
    print("Stream died!")
```

**Result**:
```
Start
Middle
Stream died!
```

The UI must be ready to handle a half-finished message.

---

## 2. Yielding Errors (The "Pink Box")

Instead of raising an exception (which might crash the client's socket connection), **yield an error object**.

```python
async def safe_stream():
    try:
        # ... generate ...
    except Exception as e:
        yield {"type": "error", "content": str(e)}
```

The Client UI sees this special chunk and renders a red error box inside the chat bubble.

---

## 3. Timeout Handling (Iterator Timeout)

Standard timeouts usually apply to the *whole request*. For streams, you want a timeout *between chunks*.

```python
import asyncio

async for chunk in asyncio.wait_for(stream, timeout=5.0):
    # This might fail if the stream simply pauses for >5s
    pass
```

Actually, you need to wrap the iterator `__next__`. This is complex in raw Python but easier with library helpers like `async-timeout`.

---

## 4. Fallback Streams

If Stream A fails instantly, try Stream B.

```python
try:
    async for c in stream_a(): yield c
except:
    async for c in stream_b(): yield c
```

Note: If Stream A yielded 5 tokens and *then* failed, the user sees: "Hello wor... [Backup Message]". This jarring, but better than nothing.

---

## Quick Reference

| Strategy | Action |
|----------|--------|
| **Catch** | Wrap the `async for` loop in try/except |
| **Yield Error** | Convert exceptions to visible messages |
| **Partial UI** | Ensure UI doesn't break on partial JSON |
