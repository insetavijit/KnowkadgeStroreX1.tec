| **Subtopic**                                   | **Focus & Purpose**                     | **Key Concepts / Details**                                                    | **One-Line Recall**                                             |
| ---------------------------------------------- | --------------------------------------- | ----------------------------------------------------------------------------- | --------------------------------------------------------------- |
| **LC10.7.4.1 API Keys**                        | Secrets                                 | env vars (OPENAI_API_KEY) vs passing in constructor                           | Use env vars for secrets; easier than passing args.             |
| **LC10.7.4.2 .env Files**                      | Development                             | Loading .env with dotenv                                                      | Load local secrets from .env files during dev.                  |
| **LC10.7.4.3 Runtime Injection**               | Security                                | Passing API keys via config for multi-tenant apps                             | Inject API keys via config for multi-tenant security.           |
| **LC10.7.4.4 Global Settings**                 | Debugging                               | LANGCHAIN_TRACING_V2, LANGCHAIN_DEBUG                                         | Use standard env vars to enable global debugging tools.         |
| **LC10.7.4.5 Pydantic BaseSettings**           | Structuring                             | Using BaseSettings to manage app configuration objects                        | Use Pydantic to validate your environment configuration.        |

# Environment Configuration: The Outer Shell

Before the code runs, the Environment exists.

---

## 1. Secrets (API Keys)

LangChain components check `os.environ` by default.

*   `ChatOpenAI()` -> checks `OPENAI_API_KEY`.
*   `ChatAnthropic()` -> checks `ANTHROPIC_API_KEY`.

**Best Practice**: Do NOT commit keys. Use `.env`.

---

## 2. Runtime Injection (Multi-Tenant)

If you are a SaaS, you can't use *your* `OPENAI_API_KEY`. You need the *User's key*.

Most LLM Runnables accept `api_key` in the constructor, but you can also configure it via `configurable_fields` or passing it in specific `input` slots (less secure).

**Better**:

```python
# Some classes support passing key via config or runtime options
# Or create the model instance AT RUNTIME inside a lambda
def get_model(x, config):
    key = config["metadata"]["api_key"]
    return ChatOpenAI(api_key=key).invoke(x)
```

---

## 3. Global Debugging Flags

Set these in your shell or `.env`.

*   `LANGCHAIN_TRACING_V2=true`: Turns on LangSmith.
*   `LANGCHAIN_API_KEY=...`: Authentication for LangSmith.
*   `LANGCHAIN_DEBUG=true`: Prints EVERY step to console (Verbose).

---

## Quick Reference

| Var | Purpose |
|-----|---------|
| **OPENAI_API_KEY** | Model auth |
| **LANGCHAIN_TRACING_V2** | Observability |
| **LANGCHAIN_PROJECT** | Group runs in LangSmith |
| **LANGCHAIN_DEBUG** | Print debug logs |
