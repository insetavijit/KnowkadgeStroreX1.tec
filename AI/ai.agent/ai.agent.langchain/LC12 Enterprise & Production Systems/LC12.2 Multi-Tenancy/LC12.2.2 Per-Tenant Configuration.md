| **Subtopic** | **Focus** | **Key Concepts** | **One-Line Recall** |
|---|---|---|---|
| **LC12.2.2.1 Configuration Storage** | Management | Where to store tenant settings | Use database or config service. |
| **LC12.2.2.2 LLM Model Selection** | Customization | Different models per tenant | Allow tenants to choose models. |
| **LC12.2.2.3 Prompt Templates** | Content | Tenant-specific prompts | Custom system prompts per tenant. |
| **LC12.2.2.4 Feature Flags** | Control | Enable/disable features | Control rollout per tenant. |
| **LC12.2.2.5 Rate Limits** | Quotas | Per-tenant usage limits | Enforce usage quotas. |

# Per-Tenant Configuration: Customization at Scale

Managing tenant-specific settings and customization.

---

## 1. Configuration Storage

```python
from pydantic import BaseModel

class TenantConfig(BaseModel):
    tenant_id: str
    model: str = "gpt-4o-mini"
    max_tokens: int = 1000
    temperature: float = 0.7
    rate_limit_per_minute: int = 60
    features: dict = {}

class ConfigService:
    def __init__(self, db):
        self.db = db
    
    def get_config(self, tenant_id: str) -> TenantConfig:
        row = self.db.query(
            "SELECT config FROM tenant_configs WHERE tenant_id = %s",
            (tenant_id,)
        ).fetchone()
        
        return TenantConfig(**row['config']) if row else TenantConfig(tenant_id=tenant_id)
    
    def update_config(self, tenant_id: str, config: TenantConfig):
        self.db.execute(
            "INSERT INTO tenant_configs (tenant_id, config) VALUES (%s, %s) ON CONFLICT (tenant_id) DO UPDATE SET config = %s",
            (tenant_id, config.dict(), config.dict())
        )
```

---

## 2. Per-Tenant LLM Model

```python
class TenantAwareLLMFactory:
    def get_llm(self, tenant_id: str):
        config = config_service.get_config(tenant_id)
        
        # Different model per tenant
        if config.model == "gpt-4o":
            return ChatOpenAI(model="gpt-4o", temperature=config.temperature)
        elif config.model == "claude-3":
            return ChatAnthropic(model="claude-3-sonnet", temperature=config.temperature)
        else:
            return ChatOpenAI(model="gpt-4o-mini", temperature=config.temperature)

# Usage
@app.post("/query")
@require_tenant
async def query(tenant_id: str, request: QueryRequest):
    llm = llm_factory.get_llm(tenant_id)
    response = await llm.ainvoke(request.query)
    return {"answer": response.content}
```

---

## 3. Custom Prompt Templates

```python
class TenantPromptManager:
    def get_system_prompt(self, tenant_id: str) -> str:
        config = config_service.get_config(tenant_id)
        
        # Custom prompt per tenant
        custom_prompt = config.features.get("system_prompt")
        if custom_prompt:
            return custom_prompt
        
        # Default
        return "You are a helpful assistant."

# Usage
messages = [
    SystemMessage(content=prompt_manager.get_system_prompt(tenant_id)),
    HumanMessage(content=user_query)
]
```

---

## 4. Feature Flags

```python
class FeatureFlags:
    def __init__(self, tenant_id: str):
        self.config = config_service.get_config(tenant_id)
    
    def is_enabled(self, feature: str) -> bool:
        return self.config.features.get(feature, False)

# Usage
@app.post("/advanced-search")
@require_tenant
async def advanced_search(tenant_id: str, query: str):
    flags = FeatureFlags(tenant_id)
    
    if not flags.is_enabled("advanced_search"):
        abort(403, "Feature not enabled for this tenant")
    
    # Process advanced search
    return await process_advanced_search(query, tenant_id)
```

---

## 5.  Rate Limiting

```python
from redis import Redis
import time

class TenantRateLimiter:
    def __init__(self, redis_client: Redis):
        self.redis = redis_client
    
    def check_limit(self, tenant_id: str) -> bool:
        config = config_service.get_config(tenant_id)
        limit = config.rate_limit_per_minute
        
        key = f"rate_limit:{tenant_id}:{int(time.time() // 60)}"
        
        current = self.redis.incr(key)
        if current == 1:
            self.redis.expire(key, 60)
        
        return current <= limit

# Middleware
@app.before_request
def check_rate_limit():
    tenant_id = get_tenant_from_request(request)
    
    if not rate_limiter.check_limit(tenant_id):
        abort(429, "Rate limit exceeded")
```

---

## Quick Reference

| Config Type | Storage | Update Frequency |
|-------------|---------|------------------|
| **Model choice** | Database | Rarely |
| **Prompts** | Database or files | Occasionally |
| **Feature flags** | Redis/Database | Frequently |
| **Rate limits** | Database | Rarely |
