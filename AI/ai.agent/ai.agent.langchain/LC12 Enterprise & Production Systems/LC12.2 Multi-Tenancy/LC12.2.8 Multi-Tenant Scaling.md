| **Subtopic** | **Focus** |  **Key Concepts** | **One-Line Recall** |
|---|---|---|---|
| **LC12.2.8.1 Resource Quotas** | Limits | CPU, memory, storage per tenant | Set hard limits per tenant. |
| **LC12.2.8.2 Noisy Neighbor** | Problem | One tenant affects others | Isolate tenant resources. |
| **LC12.2.8.3 Fair Queuing** | Pattern | Equal opportunity to process | Queue tenant requests fairly. |
| **LC12.2.8.4 Tenant Prioritization** | Strategy | Premium tenants get priority | Prioritize by tier. |
| **LC12.2.8.5 Horizontal Scaling** | Architecture | Scale tenant capacity | Add resources as tenants grow. |

# Multi-Tenant Scaling: Growing with Tenants

Scaling multi-tenant systems effectively.

---

## 1. Resource Quotas (Kubernetes)

```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: tenant-abc-quota
  namespace: tenant-abc
spec:
  hard:
    requests.cpu: "10"
    requests.memory: 20Gi
    requests.storage: 100Gi
    persistentvolumeclaims: "10"
    pods: "50"
```

```python
# Application-level quotas
class TenantResourceManager:
    def can_execute(self, tenant_id: str) -> bool:
        current = self.get_current_usage(tenant_id)
        quota = self.get_quota(tenant_id)
        
        return (
            current["concurrent_requests"] < quota["max_concurrent"] and
            current["daily_requests"] < quota["max_daily_requests"]
        )
```

---

## 2. Noisy Neighbor Prevention

```python
from concurrent.futures import ThreadPoolExecutor

class TenantIsolatedExecutor:
    def __init__(self):
        # Separate thread pool per tenant
        self.pools = {}
        self.max_workers_per_tenant = 5
    
    def get_executor(self, tenant_id: str) -> ThreadPoolExecutor:
        if tenant_id not in self.pools:
            self.pools[tenant_id] = ThreadPoolExecutor(
                max_workers=self.max_workers_per_tenant,
                thread_name_prefix=f"tenant-{tenant_id}"
            )
        return self.pools[tenant_id]
    
    async def execute(self, tenant_id: str, task):
        executor = self.get_executor(tenant_id)
        return await executor.submit(task)

# Usage
@app.post("/query")
@require_tenant
async def query(tenant_id: str, request: QueryRequest):
    # Execute in tenant-specific pool
    result = await executor.execute(
        tenant_id,
        lambda: process_query(request.query)
    )
    return result
```

---

## 3. Fair Queuing

```python
from collections import defaultdict, deque

class FairQueue:
    def __init__(self):
        self.queues = defaultdict(deque)  # tenant_id -> queue
        self.current_tenant = 0
        self.tenant_ids = []
    
    def enqueue(self, tenant_id: str, task):
        if tenant_id not in self.tenant_ids:
            self.tenant_ids.append(tenant_id)
        
        self.queues[tenant_id].append(task)
    
    def dequeue(self):
        """Round-robin across tenants."""
        if not self.tenant_ids:
            return None
        
        # Try each tenant in order
        for _ in range(len(self.tenant_ids)):
            tenant_id = self.tenant_ids[self.current_tenant]
            self.current_tenant = (self.current_tenant + 1) % len(self.tenant_ids)
            
            if self.queues[tenant_id]:
                return self.queues[tenant_id].popleft()
        
        return None

# Worker
async def process_queue():
    while True:
        task = fair_queue.dequeue()
        if task:
            await task()
        else:
            await asyncio.sleep(0.1)
```

---

## 4. Tenant Prioritization

```python
import heapq

class PriorityQueue:
    def __init__(self):
        self.heap = []
    
    def enqueue(self, tenant_id: str, priority: int, task):
        # Lower number = higher priority
        heapq.heappush(self.heap, (priority, tenant_id, task))
    
    def dequeue(self):
        if self.heap:
            priority, tenant_id, task = heapq.heappop(self.heap)
            return task
        return None

def get_tenant_priority(tenant_id: str) -> int:
    config = config_service.get_config(tenant_id)
    return {
        "enterprise": 1,
        "professional": 2,
        "standard": 3,
        "trial": 4
    }.get(config.plan, 5)

# Usage
@app.post("/query")
@require_tenant
async def query(tenant_id: str, request: QueryRequest):
    priority = get_tenant_priority(tenant_id)
    
    priority_queue.enqueue(
        tenant_id,
        priority,
        lambda: process_query(tenant_id, request.query)
    )
```

---

## 5. Scaling Strategies

```python
# Horizontal scaling based on tenant count
class AutoScaler:
    async def check_scaling_needs(self):
        tenant_count = await tenant_service.count_active()
        
        # Scale API servers
        desired_replicas = max(2, tenant_count // 50)  # 1 replica per 50 tenants
        await self.scale_deployment("langchain-api", desired_replicas)
        
        # Scale worker pools
        worker_replicas = max(3, tenant_count // 20)
        await self.scale_deployment("workers", worker_replicas)
    
    async def scale_deployment(self, name: str, replicas: int):
        # Kubernetes scaling
        await k8s_client.patch_deployment_scale(name, replicas)

# Shard tenants across instances
class TenantSharding:
    def get_shard(self, tenant_id: str, num_shards: int) -> int:
        return hash(tenant_id) % num_shards
    
    def route_request(self, tenant_id: str):
        shard = self.get_shard(tenant_id, TOTAL_SHARDS)
        endpoint = SHARD_ENDPOINTS[shard]
        return endpoint
```

---

## Quick Reference

| Pattern | Purpose |
|---------|---------|
| **Quotas** | Hard limits per tenant |
| **Isolation** | Prevent interference |
| **Fair Queue** | Equal access |
| **Priority** | Differentiate service levels |
| **Sharding** | Distribute tenants |
