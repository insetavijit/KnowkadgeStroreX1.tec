| **Subtopic** | **Focus** | **Key Concepts** | **One-Line Recall** |
|---|---|---|---|
| **LC12.4.4** | Reasoning | Show how decisions were made | Explain AI outputs. |
| **LC12.4.5** | Chain Tracing | Log chain steps | Record intermediate steps. |
| **LC12.4.6** | User-Facing | Present explanations | Show users why. |

# Explainability

```python
from langchain.callbacks import StdOutCallbackHandler

class ExplainabilityCallback(StdOutCallbackHandler):
    def __init__(self):
        self.steps = []
    
    def on_chain_start(self, serialized, inputs, **kwargs):
        self.steps.append({"type": "chain_start", "inputs": inputs})
    
    def on_llm_start(self, serialized, prompts, **kwargs):
        self.steps.append({"type": "llm_call", "prompts": prompts})
    
    def on_chain_end(self, outputs, **kwargs):
        self.steps.append({"type": "chain_end", "outputs": outputs})

# Usage
callback = ExplainabilityCallback()
result = chain.invoke(query, config={"callbacks": [callback]})

# Show reasoning
explanation = {
    "answer": result,
    "reasoning_steps": callback.steps,
    "sources": docs
}
```

**Quick Ref:** Log chain steps, show sources, explain reasoning for transparency.
